"""
XTTS-v2 íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ê°„í¸ API)
"""
import torch
import torchaudio
import os
from pathlib import Path
from dataclasses import dataclass

# TTS ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.insert(0, str(Path("xtts_finetune_repo/TTS").resolve()))

from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts


@dataclass
class TTSParams:
    """TTS ìƒì„± íŒŒë¼ë¯¸í„°
    
    ì£¼ìš” íŒŒë¼ë¯¸í„°:
    - temperature: 0.1~1.0 (ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì , ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘í•¨)
    - top_p: 0.3~0.95 (ìƒ˜í”Œë§ ë²”ìœ„)
    - top_k: ìƒìœ„ Kê°œ í† í°ë§Œ ê³ ë ¤
    - length_penalty: ë‚®ì„ìˆ˜ë¡ ê¸¸ì–´ì§ (0.5=ê¸¸ê²Œ, 1.0=ì¤‘ë¦½, 2.0=ì§§ê²Œ) âš ï¸
    - repetition_penalty: 2.0~7.0 (ë†’ì„ìˆ˜ë¡ ë°˜ë³µ ì ìŒ, ë„ˆë¬´ ë†’ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ)
    - do_sample: True=ìƒ˜í”Œë§, False=greedy
    - speed: 0.5~2.0 (ì†ë„ ì¡°ì ˆ, 1.0=ê¸°ë³¸)
    - min_length: ìµœì†Œ ìƒì„± í† í° ìˆ˜ (ê¸¸ì´ ë³´ì¥) â­
    - max_new_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
    """
    # ê¸°ë³¸ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
    temperature: float = 0.7
    top_p: float = 0.85
    top_k: int = 50
    
    # ê¸¸ì´ ì¡°ì ˆ íŒŒë¼ë¯¸í„°
    length_penalty: float = 1.0      # âš ï¸ ë‚®ì„ìˆ˜ë¡ ê¸¸ê²Œ ìƒì„±!
    repetition_penalty: float = 5.0
    min_length: int = None           # â­ ìµœì†Œ í† í° ìˆ˜ (None=ì œí•œ ì—†ìŒ)
    max_new_tokens: int = None       # ìµœëŒ€ í† í° ìˆ˜ (None=ê¸°ë³¸ê°’ ì‚¬ìš©)
    
    # ê³ ê¸‰ ì˜µì…˜
    do_sample: bool = True
    speed: float = 1.0
    enable_text_splitting: bool = False
    
    def __str__(self):
        parts = [
            f"temp={self.temperature}",
            f"top_p={self.top_p}",
            f"len_penalty={self.length_penalty}",
            f"rep_penalty={self.repetition_penalty}",
        ]
        if self.min_length is not None:
            parts.append(f"min_len={self.min_length}")
        if self.speed != 1.0:
            parts.append(f"speed={self.speed}")
        return f"TTSParams({', '.join(parts)})"


# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
CHECKPOINT_DIR = Path("checkpoints/GPT_XTTS_FT-November-25-2025_12+17AM-8e59ec3")
CHECKPOINT_PATH = CHECKPOINT_DIR / "checkpoint_4000.pth"
CONFIG_PATH = CHECKPOINT_DIR / "config.json"
VOCAB_PATH = Path("checkpoints/XTTS_v2.0_original_model_files/vocab.json")

# ì¶œë ¥ ê²½ë¡œ
OUTPUT_DIR = Path("output_finetuned")
OUTPUT_DIR.mkdir(exist_ok=True)

def load_finetuned_model():
    """íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ"""
    print("=" * 60)
    print("íŒŒì¸íŠœë‹ëœ XTTS-v2 ëª¨ë¸ ë¡œë”©...")
    print("=" * 60)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}")
    
    # Config ë¡œë“œ
    print(f"\n[1/3] Config ë¡œë“œ: {CONFIG_PATH}")
    config = XttsConfig()
    config.load_json(str(CONFIG_PATH))
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    print(f"[2/3] ëª¨ë¸ ì´ˆê¸°í™”...")
    model = Xtts.init_from_config(config)
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    print(f"[3/3] ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {CHECKPOINT_PATH}")
    model.load_checkpoint(
        config,
        checkpoint_dir=str(CHECKPOINT_DIR),
        checkpoint_path=str(CHECKPOINT_PATH),
        vocab_path=str(VOCAB_PATH),
        use_deepspeed=False
    )
    
    model.to(device)
    print("\nâœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n")
    
    return model, config, device


def load_original_model():
    """ì›ë³¸ XTTS-v2 ëª¨ë¸ ë¡œë“œ (íŒŒì¸íŠœë‹ ì•ˆ ëœ ë²„ì „)"""
    print("=" * 60)
    print("ì›ë³¸ XTTS-v2 ëª¨ë¸ ë¡œë”©...")
    print("=" * 60)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Device: {device}")
    
    # TTS APIë¡œ ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    from TTS.api import TTS
    
    print("\nì›ë³¸ XTTS-v2 ë‹¤ìš´ë¡œë“œ/ë¡œë“œ ì¤‘...")
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
    
    print("âœ… ì›ë³¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n")
    
    return tts, device


def generate_speech_finetuned(
    model, 
    config, 
    device, 
    text: str,
    reference_audio_path: Path,
    output_path: Path,
    params: TTSParams = None
):
    """
    íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ìŒì„± ìƒì„±
    
    Args:
        model: ë¡œë“œëœ XTTS ëª¨ë¸
        config: ëª¨ë¸ config
        device: ë””ë°”ì´ìŠ¤ (cuda/cpu)
        text: ìƒì„±í•  í…ìŠ¤íŠ¸
        reference_audio_path: ë³´ì´ìŠ¤ í´ë¡œë‹ì— ì‚¬ìš©í•  ì°¸ì¡° ì˜¤ë””ì˜¤ ê²½ë¡œ
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        params: TTS íŒŒë¼ë¯¸í„° (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if params is None:
        params = TTSParams()
    
    print(f"\n{'='*60}")
    print(f"[íŒŒì¸íŠœë‹ ëª¨ë¸] í…ìŠ¤íŠ¸: {text}")
    print(f"ì°¸ì¡° ì˜¤ë””ì˜¤: {reference_audio_path.name}")
    print(f"íŒŒë¼ë¯¸í„°: {params}")
    print(f"{'='*60}\n")
    
    # Speaker conditioning ì¶”ì¶œ (ë³´ì´ìŠ¤ í´ë¡œë‹)
    print("Speaker embedding ì¶”ì¶œ ì¤‘...")
    gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(
        audio_path=str(reference_audio_path),
        gpt_cond_len=config.gpt_cond_len,
        max_ref_length=config.max_ref_len,
        sound_norm_refs=config.sound_norm_refs,
    )
    
    # ìŒì„± ìƒì„±
    print("ìŒì„± ìƒì„± ì¤‘...")
    
    # HuggingFace generate kwargs ì¤€ë¹„
    hf_generate_kwargs = {}
    if params.min_length is not None:
        hf_generate_kwargs['min_length'] = params.min_length
    if params.max_new_tokens is not None:
        hf_generate_kwargs['max_new_tokens'] = params.max_new_tokens
    
    out = model.inference(
        text=text,
        language="ko",
        gpt_cond_latent=gpt_cond_latent,
        speaker_embedding=speaker_embedding,
        temperature=params.temperature,
        length_penalty=params.length_penalty,
        repetition_penalty=params.repetition_penalty,
        top_k=params.top_k,
        top_p=params.top_p,
        do_sample=params.do_sample,
        speed=params.speed,
        enable_text_splitting=params.enable_text_splitting,
        **hf_generate_kwargs,
    )
    
    # ì €ì¥
    wav = torch.tensor(out["wav"]).unsqueeze(0)
    torchaudio.save(str(output_path), wav, 24000)
    
    # ê¸¸ì´ ì •ë³´ ì¶œë ¥
    duration = len(wav[0]) / 24000  # ìƒ˜í”Œ ìˆ˜ / ìƒ˜í”Œë§ ë ˆì´íŠ¸
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"   ê¸¸ì´: {duration:.2f}ì´ˆ\n")
    
    return output_path


def generate_speech_original(
    tts,
    device,
    text: str,
    reference_audio_path: Path,
    output_path: Path,
    params: TTSParams = None
):
    """
    ì›ë³¸ ëª¨ë¸ë¡œ ìŒì„± ìƒì„±
    
    Args:
        tts: TTS API ê°ì²´
        device: ë””ë°”ì´ìŠ¤ (cuda/cpu)
        text: ìƒì„±í•  í…ìŠ¤íŠ¸
        reference_audio_path: ë³´ì´ìŠ¤ í´ë¡œë‹ì— ì‚¬ìš©í•  ì°¸ì¡° ì˜¤ë””ì˜¤ ê²½ë¡œ
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        params: TTS íŒŒë¼ë¯¸í„° (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
    
    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if params is None:
        params = TTSParams()
    
    print(f"\n{'='*60}")
    print(f"[ì›ë³¸ ëª¨ë¸] í…ìŠ¤íŠ¸: {text}")
    print(f"ì°¸ì¡° ì˜¤ë””ì˜¤: {reference_audio_path.name}")
    print(f"íŒŒë¼ë¯¸í„°: {params}")
    print(f"{'='*60}\n")
    
    print("ìŒì„± ìƒì„± ì¤‘...")
    # TTS API ì‚¬ìš©
    wav = tts.tts(
        text=text,
        speaker_wav=str(reference_audio_path),
        language="ko",
        temperature=params.temperature,
        length_penalty=params.length_penalty,
        repetition_penalty=params.repetition_penalty,
        top_k=params.top_k,
        top_p=params.top_p,
    )
    
    # ì €ì¥
    import numpy as np
    wav_tensor = torch.FloatTensor(wav).unsqueeze(0)
    torchaudio.save(str(output_path), wav_tensor, 24000)
    
    # ê¸¸ì´ ì •ë³´ ì¶œë ¥
    duration = len(wav_tensor[0]) / 24000
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"   ê¸¸ì´: {duration:.2f}ì´ˆ\n")
    
    return output_path


def main():
    """
    íŒŒì¸íŠœë‹ ëª¨ë¸ vs ì›ë³¸ ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸
    
    ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    """
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    test_text = "ì•ˆë…•í•˜ì„¸ìš”. ì¹´ë¦¬ë‚˜ì…ë‹ˆë‹¤."
    test_reference = Path("dataset/wavs/karina-tts-file_0900.wav")
    
    
    finetuned_model, finetuned_config, device = load_finetuned_model()
    
    generate_speech_finetuned(
        finetuned_model, finetuned_config, device,
        text=test_text,
        reference_audio_path=test_reference,
        output_path=OUTPUT_DIR / "example_finetuned.wav",
        params=TTSParams(
            temperature=0.35,        # ì•½ê°„ ì˜¬ë¦¼ (ì•ˆì •ì„± ìœ ì§€í•˜ë©´ì„œ í‘œí˜„ë ¥)
            top_p=0.65,              # ì•½ê°„ ì˜¬ë¦¼
            repetition_penalty=3.0,  # ì ì ˆí•œ ë°˜ë³µ ë°©ì§€
            length_penalty=0.8      # ì•½ê°„ ê¸¸ê²Œ
        )
    )
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del finetuned_model
    torch.cuda.empty_cache()
    
    original_tts, device = load_original_model()
    
    # ì›ë³¸ ëª¨ë¸ì€ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œë§Œ í…ŒìŠ¤íŠ¸
    print("\nğŸ“Œ [í…ŒìŠ¤íŠ¸ 2-1] ì›ë³¸ ëª¨ë¸ (ê¸°ë³¸)")
    generate_speech_original(
        original_tts, device,
        text=test_text,
        reference_audio_path=test_reference,
        output_path=OUTPUT_DIR / "original_default.wav",
        params=TTSParams(
            temperature=0.5,
            top_p=0.6,
            repetition_penalty=7.0
        )
    )
    
    # ========================================
    # ì™„ë£Œ ë° ìš”ì•½
    # ========================================
    print("\n" + "=" * 70)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)
    print(f"ğŸ“‚ ì¶œë ¥ í´ë”: {OUTPUT_DIR.absolute()}\n")
    print("íŒŒì¸íŠœë‹ ëª¨ë¸:")
    print("  - finetuned_1_default.wav       (ê¸°ë³¸ ì„¤ì • - ì§§ê²Œ ìƒì„±)")
    print("  - finetuned_2_long_penalty.wav  (length_penalty ë‚®ì¶¤)")
    print("  - finetuned_3_min_length.wav    (min_length ë³´ì¥)")
    print("  - finetuned_4_balanced.wav      (â­ ì¶”ì²œ ì„¤ì •)")
    print("\nì›ë³¸ ëª¨ë¸:")
    print("  - original_default.wav          (ë¹„êµìš©)")
    print("\n" + "=" * 70)
    print("ğŸ§ ì¶”ì²œ: finetuned_4_balanced.wavë¥¼ ë¨¼ì € ë“¤ì–´ë³´ì„¸ìš”!")
    print("\nğŸ’¡ íŒŒë¼ë¯¸í„° ê°€ì´ë“œ:")
    print("  - length_penalty: ë‚®ì„ìˆ˜ë¡ ê¸¸ê²Œ (0.5~0.8 ì¶”ì²œ)")
    print("  - repetition_penalty: 3.0~5.0 (ì•ˆì •ì„±ê³¼ ë°˜ë³µë°©ì§€ ê· í˜•)")
    print("  - min_length: ìµœì†Œ í† í° ìˆ˜ (80~120 ì¶”ì²œ)")
    print("  - temperature: 0.5~0.7 (ì•ˆì •ì„±)")
    print("=" * 70)

if __name__ == "__main__":
    main()

